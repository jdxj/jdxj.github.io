---
title: "4 瞬时响应: 网站的高性能架构"
date: 2023-07-22T13:21:45+08:00
tags:
  - raid
---

网站性能是客观的指标，可以具体体现到响应时间、吞吐量等技术指标，同时也是主观的感受，而感受则是一种与具体参与者相关的微妙的东西，用户的感受和工程师
的感受不同，不同的用户感受也不同。

## 4.1 网站性能测试

性能测试是性能优化的前提和基础，也是性能优化结果的检查和度量标准。不同视角下的网站性能有不同的标准，也有不同的优化手段。

### 4.1.1 不同视角下的网站性能

**用户视角的网站性能**

从用户角度，网站性能就是用户在浏览器上直观感受到的网站响应速度快还是慢。用户感受到的时间，包括用户计算机和网站服务器通信的时间、网站服务器处理的时
间、用户计算机浏览器构造请求解析响应数据的时间

图4.1 用户视角的网站性能

![](https://res.weread.qq.com/wrepub/epub_773202_14)

在实践中，使用一些前端架构优化手段，通过优化页面HTML式样、利用浏览器端的并发和异步特性、调整浏览器缓存策略、使用CDN服务、反向代理等手段，使浏览器
尽快地显示用户感兴趣的内容、尽可能近地获取页面内容，即使不优化应用程序和架构，也可以很大程度地改善用户视角下的网站性能。

**开发人员视角的网站性能**

开发人员关注的主要是应用程序本身及其相关子系统的性能，包括响应延迟、系统吞吐量、并发处理能力、系统稳定性等技术指标。主要的优化手段有使用缓存加速数
据读取，使用集群提高吞吐能力，使用异步消息加快请求响应及实现削峰，使用代码优化手段改善程序性能。

**运维人员视角的网站性能**

运维人员更关注基础设施性能和资源利用率，如网络运营商的带宽能力、服务器硬件的配置、数据中心网络架构、服务器和网络带宽的资源利用率等。主要优化手段有
建设优化骨干网、使用高性价比定制服务器、利用虚拟化技术优化资源利用等。

### 4.1.2 性能测试指标

**响应时间**

表4.1 常用系统操作响应时间表

![](https://res.weread.qq.com/wrepub/epub_773202_15)

如果测试目标操作本身需要花费的时间极少，比如几微秒，那么测试程序就无法测试得到系统的响应时间。实践中通常采用的办法是重复请求，比如一个请求操作重复
执行一万次，测试一万次执行需要的总响应时间之和，然后除以一万，得到单次请求的响应时间。

**并发数**

指系统能够同时处理请求的数目，这个数字也反映了系统的负载特性。对于网站而言，并发数即网站并发用户数，指同时提交请求的用户数目。

测试程序通过多线程模拟并发用户的办法来测试系统的并发处理能力，为了真实模拟用户行为，测试程序并不是启动多线程然后不停地发送请求，而是在两次请求之间
加入一个随机等待时间，这个时间被称作思考时间。

**吞吐量**

指单位时间内系统处理的请求数量，体现系统的整体处理能力。对于网站，可以用“请求数/秒”或是“页面数/秒”来衡量，也可以用“访问人数/天”或是
“处理的业务数/小时”等来衡量。TPS（每秒事务数）是吞吐量的一个常用量化指标，此外还有HPS（每秒HTTP请求数）、QPS（每秒查询数）等。

网站性能优化的目的，除了改善用户体验的响应时间，还要尽量提高系统吞吐量，最大限度利用服务器资源。

**性能计数器**

它是描述服务器或操作系统性能的一些数据指标。包括System Load、对象与线程数、内存使用、CPU使用、磁盘与网络I/O等指标。这些指标也是系统监控的重要参
数，对这些指标设置报警阈值，当监控系统发现性能计数器超过阈值时，就向运维和开发人员报警，及时发现处理系统异常。

### 4.1.3 性能测试方法

**性能测试**

以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系统在资源可接受范围内，是否能达到性能预期。

**负载测试**

对系统不断地增加并发请求以增加系统压力，直到系统的某项或多项性能指标达到安全临界值，如某种资源已经呈饱和状态，这时继续对系统施加压力，系统的处理能
力不但不能提高，反而会下降。

**压力测试**

超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理任何请求，以此获得系统最大压力承受能力。

**稳定性测试**

被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力，使系统运行一段较长时间，以此检测系统是否稳定。在不同生产环境、不同时间点的请求
压力是不均匀的，呈波浪特性，因此为了更好地模拟生产环境，稳定性测试也应不均匀地对系统施加压力。

图4.3 性能测试曲线

![](https://res.weread.qq.com/wrepub/epub_773202_17)

图4.4 并发用户访问响应时间曲线

![](https://res.weread.qq.com/wrepub/epub_773202_18)

### 4.1.4 性能测试报告

表4.2 性能测试结果报告

![](https://res.weread.qq.com/wrepub/epub_773202_19)

### 4.1.5 性能优化策略

**1. 性能分析**

必须对请求经历的各个环节进行分析，排查可能出现性能瓶颈的地方，定位问题。

检查请求处理的各个环节的日志，分析哪个环节响应时间不合理、超过预期；然后检查监控数据，分析影响性能的主要因素是内存、磁盘、网络、还是CPU，是代码问
题还是架构设计不合理，或者系统资源确实不足。

**2. 性能优化**

根据网站分层架构，可分为Web前端性能优化、应用服务器性能优化、存储服务器性能优化3大类。

## 4.2 Web前端性能优化

### 4.2.1 浏览器访问优化

减少http请求

- 合并CSS、合并JavaScript、合并图片

使用浏览器缓存

- 使用http缓存相关头部: Cache-Control, Expires
- 静态资源文件变化需要及时应用到客户端浏览器, 可通过改变文件名实现, 而不是更新JavaScript文件内容
- 使用浏览器缓存策略的网站在更新静态资源时, 应采用批量更新的方法
  - 比如需要更新10个图标文件，不宜把10个文件一次全部更新，而是应一个文件一个文件逐步更新，并有一定的间隔时间，以免用户浏览器突然大量缓存失效，集
    中更新缓存，造成服务器负载骤增、网络堵塞的情况。

启用压缩

- 减少通信传输的数据量
- 压缩对服务器和浏览器产生一定的压力，在通信带宽良好，而服务器资源不足的情况下要权衡考虑。

CSS放在页面最上面、JavaScript放在页面最下面

- 浏览器会在下载完全部CSS之后才对整个页面进行渲染，因此最好的做法是将CSS放在页面最上面，让浏览器尽快下载CSS
- 浏览器在加载JavaScript后立即执行，有可能会阻塞整个页面，造成页面显示缓慢，因此JavaScript最好放在页面最下面。但如果页面解析时就需要用到
  JavaScript，这时放在底部就不合适了。

减少Cookie传输

- 哪些数据需要写入Cookie需要慎重考虑
- 对于某些静态资源的访问，如CSS、Script等，发送Cookie没有意义，可以考虑静态资源使用独立域名访问，避免请求静态资源时发送Cookie

### 4.2.2 CDN加速

图4.5 利用CDN的网站架构

![](https://res.weread.qq.com/wrepub/epub_773202_20)

将数据缓存在离用户最近的地方，使用户以最快速度获取数据

### 4.2.3 反向代理

图4.6 利用反向代理的网站架构

![](https://res.weread.qq.com/wrepub/epub_773202_21)

- 保护网站
- 缓存静态/动态内容
- 负载均衡

## 4.3 应用服务器性能优化

### 4.3.1 分布式缓存

**缓存的基本原理**

一方面缓存访问速度快，可以减少数据访问的时间，另一方面如果缓存的数据是经过计算处理得到的，那么被缓存的数据无需重复计算即可直接使用，因此缓存还起到
减少计算时间的作用。

- 缓存的本质是一个内存Hash表
- 网站数据访问通常遵循二八定律，即80%的访问落在20%的数据上

**合理使用缓存**

- 频繁修改的数据. 一般说来，数据的读写比在2:1以上，即写入一次缓存，在数据更新前至少读取两次，缓存才有意义。
- 没有热点的访问. 如果应用系统访问数据没有热点，不遵循二八定律，即大部分数据访问并没有集中在小部分数据上，那么缓存就没有意义，因为大部分数据还没有
  被再次访问就已经被挤出缓存了。
- 数据不一致与脏读
  - 一般会对缓存的数据设置失效时间，一旦超过失效时间，就要从数据库中重新加载。因此应用要容忍一定时间的数据不一致
  - 还有一种策略是数据更新时立即更新缓存，不过这也会带来更多系统开销和事务一致性的问题。
- 缓存可用性. 发生[缓存雪崩](https://xiaolincoding.com/redis/cluster/cache_problem.html#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9)
  不能简单地重启缓存服务器和数据库服务器来恢复网站访问。
  - 通过缓存热备等手段提高缓存可用性. 这种设计显然有违缓存的初衷，缓存根本就不应该被当做一个可靠的数据源来使用。
  - 通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。当一台缓存服务器宕机的时候，只有部分缓存数据丢失，
    重新从数据库加载这部分数据不会对数据库产生很大影响。
- 缓存预热. 新启动的缓存系统如果没有任何数据，在重建缓存数据的过程中，系统的性能和数据库负载都不太好，那么最好在缓存系统启动时就把热点数据加载好，
  这个缓存预加载手段叫作缓存预热（warm up）。
- [缓存穿透](https://xiaolincoding.com/redis/cluster/cache_problem.html#%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F).
  一个简单的对策是将不存在的数据也缓存起来（其value值为null）。

**分布式缓存架构**

- 一种是以JBoss Cache为代表的需要更新同步的分布式缓存
- 一种是以Memcached为代表的不互相通信的分布式缓存。

JBoss Cache的分布式缓存在集群中所有服务器中保存相同的缓存数据，当某台服务器有缓存数据更新的时候，会通知集群中其他机器更新缓存数据或清除缓存数据.
JBoss Cache通常将应用程序和缓存部署在同一台服务器上，应用程序可从本地快速获取缓存数据，但是这种方式带来的问题是缓存数据的数量受限于单一服务器的
内存空间，而且当集群规模较大的时候，缓存更新信息需要同步到集群所有机器，其代价惊人。因而这种方案更多见于企业应用系统中，而很少在大型网站使用。

图4.9 需要更新同步的JBoss Cache

![](https://res.weread.qq.com/wrepub/epub_773202_24)

Memcached采用一种集中式的缓存集群管理，也被称作互不通信的分布式架构方式。缓存与应用分离部署，缓存系统部署在一组专门的服务器上，应用程序通过一致性
Hash等路由算法选择缓存服务器远程访问缓存数据，缓存服务器之间不通信，缓存集群的规模可以很容易地实现扩容，具有良好的可伸缩性。

**Memcached**

图4.10 不互相通信的Memcached

![](https://res.weread.qq.com/wrepub/epub_773202_25)

虽然近些年许多NoSQL产品层出不穷，在数据持久化、支持复杂数据结构、甚至性能方面有许多产品优于Memcached，但Memcached由于其简单、稳定、专注的特点，
仍然在分布式缓存领域占据着重要地位。

### 4.3.2 异步操作

可改善网站的扩展性, 还可改善网站系统的性能

- 由于消息队列服务器处理速度远快于数据库（消息队列服务器也比数据库具有更好的伸缩性），因此用户的响应延迟可得到有效改善。
- 消息队列具有很好的削峰作用
- 由于数据写入消息队列后立即返回给用户，数据在后续的业务校验、写数据库等操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进
  行配合

### 4.3.3 使用集群

避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性

图4.15 利用负载均衡技术改善性能

![](https://res.weread.qq.com/wrepub/epub_773202_30)

### 4.3.4 代码优化

- 多线程
  - 将对象设计为无状态对象
  - 使用局部对象
  - 并发访问资源时使用锁
- 资源复用, 要尽量减少那些开销很大的系统资源的创建和销毁
  - 单例
  - 对象池
  - 线程池
- 数据结构. 在不同场景中合理使用恰当的数据结构，灵活组合各种数据结构改善数据读写和计算特性可极大优化程序的性能。
- 垃圾回收. 理解垃圾回收机制有助于程序优化和参数调优，以及编写内存安全的代码。

## 4.4 存储性能优化

### 4.4.1 机械硬盘vs. 固态硬盘

在网站应用中，大部分应用访问数据都是随机的，这种情况下SSD具有更好的性能表现。

### 4.4.2 B+树vs. LSM树

为了改善数据访问特性，文件系统或数据库系统通常会对数据排序后存储，加快数据检索速度，这就需要保证数据在不断更新、插入、删除后依然有序，传统关系数据
库的做法是使用B+树

- 由于每次磁盘访问都是随机的，而传统机械硬盘在数据随机访问时性能较差，每次数据访问都需要多次访问磁盘影响数据访问性能。

图4.20 B+树原理示意图

![](https://res.weread.qq.com/wrepub/epub_773202_35)

目前许多NoSQL产品采用LSM树作为主要数据结构

图4.21 LSM树原理示意图

![](https://res.weread.qq.com/wrepub/epub_773202_36)

数据在内存中仍然还是一棵排序树，当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定阈值后，和磁盘
上下一级的排序树合并。合并过程中，会用最新更新的数据覆盖旧的数据（或者记录为不同版本）。

当数据访问以写操作为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度地减少磁盘的访问次数，加快访问速度。

### 4.4.3 RAID vs. HDFS

图4.22 常用RAID技术原理图

![](https://res.weread.qq.com/wrepub/epub_773202_37)

假设服务器有N块磁盘。

**RAID0**

数据在从内存缓冲区写入磁盘时，根据磁盘数量将数据分成N份，这些数据同时并发写入N块磁盘，使得数据整体写入速度是一块磁盘的N倍。读取时也一样，因此
RAID0具有极快的数据读写速度，但是RAID0不做数据备份，N块磁盘中只要有一块损坏，数据完整性就被破坏，所有磁盘的数据都会损坏。

**RAID1**

数据在写入磁盘时，将一份数据同时写入两块磁盘，这样任何一块磁盘损坏都不会导致数据丢失，插入一块新磁盘就可以通过复制数据的方式自动修复，具有极高的可
靠性。

**RAID10**

结合RAID0和RAID1两种方案，将所有磁盘平均分成两份，数据同时在两份磁盘写入，相当于RAID1，但是在每一份磁盘里面的N/2块磁盘上，利用RAID0技术并发读
写，既提高可靠性又改善性能，不过RAID10的磁盘利用率较低，有一半的磁盘用来写备份数据。

**RAID3**

在数据写入磁盘的时候，将数据分成N-1份，并发写入N-1块磁盘，并在第N块磁盘记录校验数据，任何一块磁盘损坏（包括校验数据磁盘），都可以利用其他N-1块磁
盘的数据修复。

但是在数据修改较多的场景中，修改任何磁盘数据都会导致第N块磁盘重写校验数据，频繁写入的后果是第N块磁盘比其他磁盘容易损坏，需要频繁更换，所以RAID3很
少在实践中使用。

**RAID5**

RAID5和RAID3很相似，但是校验数据不是写入第N块磁盘，而是螺旋式地写入所有磁盘中。这样校验数据的修改也被平均到所有磁盘上，避免RAID3频繁写坏一块磁
盘的情况。

**RAID6**

如果数据需要很高的可靠性，在出现同时损坏两块磁盘的情况下（或者运维管理水平比较落后，坏了一块磁盘但是迟迟没有更换，导致又坏了一块磁盘），仍然需要修
复数据，这时候可以使用RAID6。

RAID6和RAID5类似，但是数据只写入N-2块磁盘，并螺旋式地在两块磁盘中写入校验信息（使用不同算法生成）。

表4.3 几种RAID技术比较

![](https://res.weread.qq.com/wrepub/epub_773202_38)

RAID技术可以通过硬件实现，比如专用的RAID卡或者主板直接支持，也可以通过软件实现。RAID技术在传统关系数据库及文件系统中应用比较广泛，但是在大型网站
比较喜欢使用的NoSQL，以及分布式文件系统中，RAID技术却遭到冷落。

在**HDFS**（Hadoop分布式文件系统）中，系统在整个存储集群的多台服务器上进行数据并发读写和备份，可以看作在服务器集群规模上实现了类似RAID的功能，
因此不需要磁盘RAID。

HDFS以块（Block）为单位管理文件内容，一个文件被分割成若干个Block，当应用程序写文件时，每写完一个Block，HDFS就将其自动复制到另外两台机器上，保
证每个Block有三个副本，即使有两台服务器宕机，数据依然可以访问，相当于实现了RAID1的数据复制功能。

图4.23 HDFS架构原理图

![](https://res.weread.qq.com/wrepub/epub_773202_39)

在HDFS中有两种重要的服务器角色：NameNode（名字服务节点）和DataNode（数据存储节点）。

- NameNode在整个HDFS中只部署一个实例，提供元数据服务，相当于操作系统中的文件分配表（FAT），管理文件名Block的分配，维护整个文件系统的目录树结构。
- DataNode则部署在HDFS集群中其他所有服务器上，提供真正的数据存储服务。

## 4.5 小结
