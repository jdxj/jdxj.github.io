---
title: "第7章 同步"
date: 2023-02-20T21:55:24+08:00
---

## 7.1 Happens Before

多核情况下避免并发读写的条件

- w happens before r。
- 没有其他针对v的写操作happens after w且before r。

图7-1 多线程并发事件示意图

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P275_11721.jpg)

### 7.1.1 并发

{{< embedcode go "code/main.go" >}}

如果编译器生成的指令与源码中语句的顺序严格一致，上述生产者协程和消费者协程在单核CPU上并发执行是可以保证结果正确的。一旦编译器对生成指令的顺序
进行优化调整，或者程序在多核CPU上执行，就不能保证结果正确了

### 7.1.2 并行

抽象地解释并发，指的是多个事件在宏观上是同时发生的，但是并不一定要在同一时刻发生，而并行就不一样了，从微观角度来看，并行的两个事件至少有某一
时刻是同时发生的，所以在单核CPU上的多线程只存在并发，不存在并行。只有在多核CPU上，线程才有可能并行执行。

## 7.2 内存乱序

- 处理器普遍具有乱序执行的特性，目的都是为了更优的性能。
- 编译器和CPU都会考虑指令间的依赖关系，在不会改变当前线程行为的前提下进行顺序调整，因此在单个线程内依然是逻辑有序的，语句间原本满足的
  happens before条件不会被破坏，但这种有序性只是在单个线程内，并不会保证线程间的有序性。

### 7.2.1 编译期乱序

指的是编译器对最终生成的机器指令进行了顺序调整

### 7.2.2 执行期乱序

CPU在执行期间也可能会对指令的顺序进行调整

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P278_11801.jpg)

协程一和协程二中的两条赋值语句形式相似，对应到x86汇编就是三条内存操作指令，按照顺序及分类分别是Store、Load、Store

图7-2 协程一和协程二的赋值语句对应的汇编指令

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P280_11851.jpg)

一般的内存属于write-back cacheable内存，简称WB内存。对于WB内存而言，Store和Load指令并不是直接操作内存中的数据的，而是先把指定的内存单元
填充到高速缓存中，然后读写高速缓存中的数据。

Load指令的大致流程是，先尝试从高速缓存中读取，如果缓存命中，则读操作就完成了。如果缓存未命中，则先填充对应的Cache Line，
然后从Cache Line中读取

图7-3 Load指令的执行流程

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P280_11855.jpg)

Store指令的大致流程类似，先尝试写高速缓存，如果缓存命中，则写操作就完成了。如果缓存未命中，则先填充对应的Cache Line，然后写到Cache Line中

图7-4 Store指令执行流程

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P281_11861.jpg)

在多核心的CPU上，Store操作会变得更复杂一些。

- 每个CPU核心都拥有自己的高速缓存，例如x86的L1 Cache。写操作会修改当前核心的高速缓存, 被修改的数据可能存在于多个核心的高速缓存中，CPU需要
  保证各个核心间的缓存一致性。
- 目前主流的缓存一致性协议是MESI协议，MESI这个名字取自缓存单元可能的4种状态，分别是已修改的Modified，独占的Exclusive，共享的Shared和无
  效的Invalid。

当一个CPU核心要对自身高速缓存的某个单元进行修改时，它需要先通知其他CPU核心把各自高速缓存中对应的单元置为Invalid，再把自己的这个单元置为
Exclusive，然后就可以进行修改了。

图7-5 一个CPU核心修改高速缓存数据单元的过程

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P281_11865.jpg)

这个过程涉及多核间的内部通信，是一个相对较慢的过程，为了避免当前核心因为等待而阻塞，CPU在设计上又引入了Store Buffer。当前核心向其他核心发出
通知以后，可以先把要写的值放在Store Buffer中，然后继续执行后面的指令，等到其他核心完成响应以后，当前核心再把Store Buffer中的值合并到高速
缓存中

图7-6 引入Store Buffer后CPU修改高速缓存数据单元的过程

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P282_11871.jpg)

虽然高速缓存会保证多核一致性，但是Store Buffer却是各个核心私有的，因此对其他核心不可见。在Store-Load乱序中，从微观时序上，Load指令可能是
在另一个线程的Store之后执行，但此时多核间通信尚未完成，对应的缓存单元还没有被置为Invalid，Store Buffer也没有被合并到高速缓存中，所以Load
读到的是修改前的值。

图7-7 写入Store Buffer后合并到高速缓存前Load数据

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P283_11877.jpg)

当协程一执行最后一条Store指令时，b就被赋值为0。同样地，协程二会将a赋值为0。即使Store Buffer合并到高速缓存，x和y都被修改为新值，也已经晚了

图7-8 合并到高速缓存后的数据状态

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P283_11880.jpg)

理论上可能出现的乱序有4种

- Load-Load，相邻的两条Load指令，后面的比前面的先读到数据。
- Load-Store，Load指令在前，Store指令在后，但是Store操作先变成全局可见，Load指令在此之后才读到数据。
- Store-Load，Store指令在前，Load指令在后，但是Load指令先读到了数据，Store操作在此之后才变成全局可见。这个我们已经在x86平台见证过了。
- Store-Store，相邻的两条Store指令，后面的比前面的先变成全局可见。

所谓的全局可见，指的是在多核CPU上对所有核心可见。

### 7.2.3 内存排序指令

执行期乱序会给结果带来很大的不确定性，这对于应用程序来讲是不能接受的，完全按照指令顺序执行又会使性能变差。为了解决这一问题，CPU提供了内存排序
指令，应用程序在必要的时候能够通过这些指令来避免发生乱序。以目前的Intel x86处理器为例，提供了LFENCE、SFENCE和MFENCE这3条内存排序指令

> 难以理解

## 7.3 常见的锁

锁需要将所有线程（或协程）对临界区的访问进行串行化处理，需要同时保证两点要求：

- 同时只能有一个线程获得锁，持有锁才能进入临界区。
- 当线程离开临界区释放锁后，线程在临界区内做的所有操作都要全局可见。

### 7.3.1 原子指令

如果CMP, JNE, MOV不在一条指令中执行, 那么加锁会出问题

图7-9 同步问题

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P288_11985.jpg)

x86就提供了CMPXCHG指令, 是Compare and Exchange的缩写，该指令有两个操作数，用于实现锁的时候，第一操作数通常是个内存地址，也称为目的操作
数，第二操作数是个通用寄存器。CMPXCHG会将AX寄存器和第一操作数进行比较，如果相等就把第二操作数复制到目的操作数中，若不相等就把目的操作数复制
到AX寄存器中。

在多核环境下，运行在不同CPU核心上的线程可能会并行加锁，不同核心同时执行CMPXCHG又会造成多个线程同时获得锁。

如何解决这个问题呢？

一种思路是，在当前核心执行CMPXCHG时，阻止其他核心执行CMPXCHG，x86汇编中的LOCK前缀用于实现这一目的。

- LOCK前缀能够应用于部分内存操作指令，最简单的解释就是LOCK前缀会让当前CPU核心在当前指令执行期间独占总线，这样其他的CPU核心就不能同时操作内
  存了。
- 事实上，只有对于不在高速缓存中的数据才会这样，对于高速缓存中的数据，LOCK前缀会通过MESI协议处理多核间缓存一致性。
- 在多核环境下，这种带有LOCK前缀的指令也被称为原子指令。

在x86CPU上，LOCK前缀同时具有内存排序的作用，相当于在应用LOCK前缀的指令之后紧接着执行了一条MFENCE指令。综上所述，原子指令既能保证只允许一个
线程进入临界区，又具有内存排序的作用，能够保证在锁的状态发生变化时，临界区中所有的修改随锁的状态一起变成全局可见。

### 7.3.2 自旋锁

自旋锁得以实现的基础是原子性的CAS操作，CAS即Compare And Swap，在x86平台上对应带有LOCK前缀的CMPXCHG指令。之所以称作自旋锁，是因为它会一
直循环尝试CAS操作直到成功，看起来就像是一直在自旋等待。

尝试一下用汇编语言基于CMPXCHG指令实现一把自旋锁

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P289_12002.jpg)

lock()和unlock()这两个函数用汇编实现

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P289_12010.jpg)

- lock()函数把锁的地址放在了BX寄存器中，把用来比较的旧值old放到了DX寄存器中，把要写入的新值new放到了CX寄存器中。
- 从标签again处开始是一个循环，每次循环开始前，把DX寄存器的值复制给AX寄存器，因为CMPXCHG隐含使用AX寄存器中的值作为比较用的旧值，并且可能会
  修改AX寄存器，所以每次循环需要重新赋值
- 这个循环不断尝试通过CMPXCHG进行加锁，成功后会通过JE指令跳出循环。能够通过JE跳出循环，这是因为CMP操作会影响标志寄存器。
- unlock()函数通过XCHG指令将锁清零，实现了解锁操作。细心的读者可能会注意到这里没有LOCK前缀，根据Intel开发者手册所讲，XCHG指令隐含了LOCK
  前缀，所以代码中不用写，依然能够起到独占总线和内存排序的作用。

事实上，atomic包中的CompareAndSwapInt32()函数和StoreInt32()函数是基于CMPXCHG和XCHG这两条汇编指令实现的，所以上述的自旋锁可以改成完全
用Go实现

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P290_12021.jpg)

在锁竞争比较激烈的场景下，这种自旋会造成CPU使用率很高，所以还要进行优化。x86专门为此提供了PAUSE指令，它一方面能够提示处理器当前正处于自旋循
环中，从而在退出循环的时候避免因检测到内存乱序而造成性能损失。另一方面，PAUSE能够大幅度减小自旋造成的CPU功率消耗，从而达到节能和减少发热的效
果。

可以把PAUSE指令加入我们汇编版本的lock()函数实现中

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P290_12029.jpg)

可以把PAUSE指令单独放在一个函数中，这样就能够跟atomic包中的函数结合使用了

![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P291_12046.jpg)
![](https://res.weread.qq.com/wrepub/CB_3300047233_Figure-P291_12055.jpg)

自旋锁的适用场景

- 不适用于单核, 因为单核系统上任一时刻只能有一个线程在运行，当前线程一直在自旋等待，而持有锁的线程得不到运行，锁就不可能被释放
- 即使是在多核环境下, 在持有锁的时间占比很小，并且活跃线程数接近CPU核心数量时，自旋锁比较高效，也就是自旋的代价小于线程切换的代价。


### 7.3.3 调度器对象

指操作系统提供的线程间同步原语

- 这些调度器对象与自旋锁的不同主要是有一个等待队列。
- 当线程获取锁失败时不会一直在那里自旋，而是挂起后进入等待队列中等待，然后系统调度器会切换到下一个可运行的线程。
- 等到持有锁的线程释放锁的时候，会按照一定的算法从等待队列中取出一个线程并唤醒它，被唤醒的线程会获得所有权，然后继续执行。
- 这些同步原语是由内核提供的，直接与系统的调度器交互，能够挂起和唤醒线程，这一点是自旋锁做不到的。
- 等待队列可以实现支持FIFO、FILO，甚至支持某种优先级策略，但是也正是由于是在内核中实现的，所以应用程序需要以系统调用的方式来使用它，这就造
  成了一定的开销。在获取锁失败的情况下还会发生线程切换，进一步增大开销。

### 7.3.4 优化的锁

将自旋锁和调度器对象结合，理论上就可以得到一把优化的锁了。加锁时首先经过自旋锁，但是需限制最大自旋次数，如果在有限次数内加锁成功也就成功了，
否则就进一步通过调度器对象将当前线程挂起。等到持有锁的线程释放锁的时候，会通过调度器对象将挂起的线程唤醒。这样就结合了二者的优点，既避免了加
锁失败立即挂起线程造成过多的上下文切换，又避免了无限制地自旋而空耗CPU，这也是如今主流的锁实现思路。

## 7.4 Go语言的同步

推荐看极客时间的[Go并发编程实战课](https://time.geekbang.org/column/intro/100061801?tab=catalog)

## 7.5 本章小结
